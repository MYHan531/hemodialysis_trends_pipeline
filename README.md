# ğŸ’‰ Hemodialysis Trends Data Pipeline (Airflow + Spark)

This project analyzes and tracks trends related to kidney disease and hemodialysis using data engineering tools like **PySpark**, **PostgreSQL**, and **Apache Airflow**. It transforms raw medical data into insights you can visualize and monitor.

---

## ğŸš€ Tech Stack

- **Python 3.11**
- **Apache Spark** for scalable data transformation
- **PostgreSQL** for storing cleaned data
- **Apache Airflow** for scheduling and monitoring the pipeline
- **Power BI** (external) for dashboarding and visualization

---

## ğŸ“ Project Structure

hemodialysis_trends_pipeline/ 
â”‚ 
â”œâ”€â”€ dags/ # Airflow DAGs (unused as of now)
â”‚     â””â”€â”€ dialysis_pipeline.py 
â”‚ 
â”œâ”€â”€ data/ 
â”‚     â”œâ”€â”€ raw/ # Original CSV
|     |     â””â”€â”€ kidney_disease.csv # Original Dataset
|     |
â”‚     â””â”€â”€ clean/ # Cleaned output 
â”‚ 
â”œâ”€â”€ scripts/
â”‚     |â”€â”€ logs/ # Log folder
|     |     â””â”€â”€ etl.log # Created by spark_transform.py
â”‚     |â”€â”€ spark_transform.py # Data cleaning transformation, loads into PostgresSQL (requires pgAdmin)
|     |â”€â”€ load_to_db.py # Deprecated, replaced by spark_transform.py
|     â””â”€â”€ transform_data.py # Also deprecated, replaced by spark_transform.py
â”‚
|â”€â”€ visualisations/
|     â””â”€â”€ Haemodialysis Patient Trends - CKD Dataset.pbix # Data Visualiser used to chart the cleaned data
|  
â”œâ”€â”€ requirements.txt 
â””â”€â”€ README.md